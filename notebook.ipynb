{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np #  manip des arrays (tableaux)\n",
    "import pandas as pd #  manip des dataframes\n",
    "import matplotlib.pyplot as plt #  construct des graphes : barplot, cammenberts\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('processed.cleveland.csv', names=['age','sex','chest pain','blood pressure(r)','cholestoral','fasting blood sugar','eleccardio results(r)','max heart rate achvd','exercise angina','ST depression (ex to r)','slope exercise ST','number of vessels','thalassemia','diagnosis'])\n",
    "df.describe()\n",
    "\n",
    "df.describe()\n",
    "df1 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(figsize=[8,6], rot=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.plotting import scatter_matrix\n",
    "# scatter_mat = scatter_matrix(df, figsize = (20,16))\n",
    "\n",
    "axes = pd.plotting.scatter_matrix(df, alpha=0.2, figsize = (16,12))\n",
    "for ax in axes.flatten():\n",
    "    ax.xaxis.label.set_rotation(90)\n",
    "    ax.yaxis.label.set_rotation(0)\n",
    "    ax.yaxis.label.set_ha('right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.gcf().subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
    "\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "            props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "            props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "            props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "            props=[('max-width', '200px'),\n",
    "            ('font-size', '12pt')])\n",
    "        ]\n",
    "        \n",
    "df_corr.style.background_gradient(cmap, axis=1).set_properties(**{'hello':'80px','font-size':'10pt'}).set_caption(\"Hover to magify\").set_precision(2).set_table_styles(magnify())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Régression linéaire ajustée au graphique précédent\n",
    "sns.regplot(x=df[\"max heart rate achvd\"], y=df[\"age\"], fit_reg=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(x='exercise angina', y='chest pain', style='o')\n",
    "sns.regplot(x=df[\"exercise angina\"], y=df[\"chest pain\"], fit_reg=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(x='exercise angina', y='chest pain', style='o')\n",
    "sns.regplot(x=df[\"cholestoral\"], y=df[\"diagnosis\"], fit_reg=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.plot(x='blood pressure(r)', y='cholestoral', style='o')\n",
    "sns.regplot(x=df[\"blood pressure(r)\"], y=df[\"cholestoral\"], fit_reg=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = df.groupby(['age'])['age'].count()\n",
    "graph.plot(kind = 'bar', figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = df.groupby(['sex'])['sex'].count()\n",
    "graph.plot(kind = 'bar', figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On nettoie les valeurs nulles\n",
    "df = df[df[\"number of vessels\"].str.contains(\"\\?\")==False]\n",
    "df = df[df[\"thalassemia\"].str.contains(\"\\?\")==False]\n",
    "\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "df_minmax = min_max.fit_transform(df)\n",
    "df_minmax = pd.DataFrame(df_minmax)\n",
    "df_minmax.boxplot(rot = 45,figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "df_scale = scale(df)\n",
    "df_scale\n",
    "pd.DataFrame(df_scale).boxplot(rot = 45,figsize=(16, 10))\n",
    "df_scale = pd.DataFrame(df_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df_minmax.iloc[:,0:13]\n",
    "y = df_minmax.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/4, random_state=42, stratify=y)\n",
    "\n",
    "# FIXME : Restore initial classes\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_scale = df_scale.iloc[:,0:13]\n",
    "y_scale = df.iloc[:,-1]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_scale, y_scale, test_size=1/4, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=15)\n",
    "knn1.fit(X_train1, y_train1)\n",
    "knn1.effective_metric_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluer avec scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred1, X_scale, y_scale scaler avec la méthode scale\n",
    "y_pred1 = knn1.predict(X_test1)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_this(y_test1,y_pred1):\n",
    "    print(metrics.accuracy_score(y_test1, y_pred1))\n",
    "    print(metrics.f1_score(y_test1, y_pred1, average='weighted'))\n",
    "\n",
    "evaluate_this(y_test1,y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraîner le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.effective_metric_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prédir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_this(y_test,y_pred):\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "evaluate_this(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to guess better K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb pour l'approche basique\n",
    "# https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/ pour le cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "neighbors = list(range(1, 50, 2))\n",
    "\n",
    "cv_scores = []\n",
    "error_rate = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(y_pred != y_test))\n",
    "\n",
    "# changing CV accuracy => to CV error\n",
    "cv_errors = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k for both methods\n",
    "cv_optimal_k = neighbors[cv_errors.index(min(cv_errors))]\n",
    "error_optimal_k = neighbors[error_rate.index(min(error_rate))]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(neighbors, cv_errors, color='green', linestyle='dashed', \n",
    "         marker='o', markersize=6)\n",
    "\n",
    "plt.plot(neighbors, error_rate, color='grey', linestyle='dashed', \n",
    "         marker='o', markersize=6)\n",
    "\n",
    "\n",
    "plt.title('CV errors AND Erros VS K')\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error rate\")\n",
    "\n",
    "print(\"Minimum CV error : \", min(cv_errors),\" % at K =\", cv_optimal_k)\n",
    "print(\"Minimum error: \", min(error_rate),\" % at K =\", error_optimal_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best K is 15 !\n",
    "\n",
    "> 5 seems good, but it is probably overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"neighbors\" : neighbors, \"CV errors\" : cv_errors, \"Errors\" : error_rate}, index=neighbors)\n",
    "# df = df.sort_values('errors', ascending=True)\n",
    "df = df.sort_values(['CV errors', 'neighbors'], ascending=[True, False])\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerun model with new K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 15\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "evaluate_this(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Fixer les valeurs des hyperparamètres à tester\n",
    "param_grid = {'n_neighbors':[3, 5, 7, 9, 11, 13, 15]}\n",
    "\n",
    "# Choisir un score à optimiser, ici l'accuracy (proportion de prédictions correctes)\n",
    "score = 'accuracy'\n",
    "\n",
    "# Créer un classifieur kNN avec recherche d'hyperparamètre par validation croisée\n",
    "clf = GridSearchCV(\n",
    "    neighbors.KNeighborsClassifier(), # un classifieur kNN\n",
    "    param_grid,     # hyperparamètres à tester\n",
    "    cv=5,           # nombre de folds de validation croisée\n",
    "    scoring=score   # score à optimiser\n",
    ")\n",
    "\n",
    "# Optimiser ce classifieur sur le jeu d'entraînement\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Afficher le(s) hyperparamètre(s) optimaux\n",
    "print(\"Meilleur(s) hyperparamètre(s) sur le jeu d'entraînement:\")\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les performances correspondantes\n",
    "print(\"Résultats de la validation croisée :\")\n",
    "for mean, std, params in zip(\n",
    "        clf.cv_results_['mean_test_score'], # score moyen\n",
    "        clf.cv_results_['std_test_score'],  # écart-type du score\n",
    "        clf.cv_results_['params']           # valeur de l'hyperparamètre\n",
    "    ):\n",
    "\n",
    "    print(\"{} = {:.3f} (+/-{:.03f}) for {}\".format(\n",
    "        score,\n",
    "        mean,\n",
    "        std*2,\n",
    "        params\n",
    "    ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La méthode OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train_scale=scale(X_train)\n",
    "X_test_scale=scale(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc=OneHotEncoder(sparse=False)\n",
    "\n",
    "df1 = df1[df1[\"number of vessels\"].str.contains(\"\\?\")==False]\n",
    "df1 = df1[df1[\"thalassemia\"].str.contains(\"\\?\")==False]\n",
    "\n",
    "X_a = df1.iloc[:,0:13]\n",
    "y_a = df1.iloc[:,-1]\n",
    "\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_a, y_a, test_size=1/4, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['age','sex','chest pain','blood pressure(r)','cholestoral',\n",
    "         'fasting blood sugar','eleccardio results(r)','max heart rate achvd','exercise angina',\n",
    "         'ST depression (ex to r)','slope exercise ST','number of vessels','thalassemia']\n",
    "\n",
    "for col in columns:\n",
    "       # creating an exhaustive list of all possible categorical values\n",
    "       data=X_train_a[[col]].append(X_test_a[[col]])\n",
    "       enc.fit(data)\n",
    "       # Fitting One Hot Encoding on train data\n",
    "       temp = enc.transform(X_train_a[[col]])\n",
    "       # Changing the encoded features into a data frame with new column names\n",
    "       temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col]\n",
    "            .value_counts().index])\n",
    "       # In side by side concatenation index values should be same\n",
    "       # Setting the index values similar to the X_train data frame\n",
    "       temp=temp.set_index(X_train_a.index.values)\n",
    "       # adding the new One Hot Encoded varibales to the train data frame\n",
    "       X_train_1=pd.concat([X_train_a,temp],axis=1)\n",
    "       # fitting One Hot Encoding on test data\n",
    "       temp = enc.transform(X_test_a[[col]])\n",
    "       # changing it into data frame and adding column names\n",
    "       temp=pd.DataFrame(temp,columns=[(col+\"_\"+str(i)) for i in data[col]\n",
    "            .value_counts().index])\n",
    "       # Setting the index for proper concatenation\n",
    "       temp=temp.set_index(X_test_a.index.values)\n",
    "       # adding the new One Hot Encoded varibales to test data frame\n",
    "       X_test_1=pd.concat([X_test_a,temp],axis=1)\n",
    "    \n",
    "X_train_scale=scale(X_train_1)\n",
    "X_test_scale=scale(X_test_1)\n",
    "# Fitting a logistic regression model\n",
    "\n",
    "for x in range(1,100):\n",
    "     y = x * 0.01\n",
    "     log=LogisticRegression(penalty='l2',C=y)\n",
    "     log.fit(X_train_scale,y_train)\n",
    "     print(accuracy_score(y_test,log.predict(X_test_scale)))\n",
    "     #print(y)\n",
    "\n",
    "#log=LogisticRegression(penalty='l2',C=1)\n",
    "#log.fit(X_train_scale,y_train_a)\n",
    "# Checking the model's accuracy\n",
    "#accuracy_score(y_test_a,log.predict(X_test_scale))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}