{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Exploration des données"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "import numpy as np #  manip des arrays (tableaux)\n",
    "import pandas as pd #  manip des dataframes\n",
    "import matplotlib.pyplot as plt #  construct des graphes : barplot, cammenberts\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('processed.cleveland.csv', names=['age','sex','chest pain','blood pressure(r)','cholestoral','fasting blood sugar','eleccardio results(r)','max heart rate achvd','exercise angina','ST depression (ex to r)','slope exercise ST','number of vessels','thalassemia','diagnosis'])\n",
    "df.describe()\n",
    "\n",
    "df.head()\n",
    "df.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.boxplot(figsize=[8,6], rot=70)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from pandas.plotting import scatter_matrix\n",
    "# scatter_mat = scatter_matrix(df, figsize = (20,16))\n",
    "\n",
    "axes = pd.plotting.scatter_matrix(df, alpha=0.2, figsize = (16,12))\n",
    "for ax in axes.flatten():\n",
    "    ax.xaxis.label.set_rotation(90)\n",
    "    ax.yaxis.label.set_rotation(0)\n",
    "    ax.yaxis.label.set_ha('right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.gcf().subplots_adjust(wspace=0, hspace=0)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_corr = df.corr()\n",
    "df_corr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
    "\n",
    "def magnify():\n",
    "    return [dict(selector=\"th\",\n",
    "            props=[(\"font-size\", \"7pt\")]),\n",
    "            dict(selector=\"td\",\n",
    "            props=[('padding', \"0em 0em\")]),\n",
    "            dict(selector=\"th:hover\",\n",
    "            props=[(\"font-size\", \"12pt\")]),\n",
    "            dict(selector=\"tr:hover td:hover\",\n",
    "            props=[('max-width', '200px'),\n",
    "            ('font-size', '12pt')])\n",
    "        ]\n",
    "        \n",
    "df_corr.style.background_gradient(cmap, axis=1).set_properties(**{'hello':'80px','font-size':'10pt'}).set_caption(\"Hover to magify\").set_precision(2).set_table_styles(magnify())\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Régression linéaire ajustée au graphique précédent\n",
    "sns.regplot(x=df[\"max heart rate achvd\"], y=df[\"age\"], fit_reg=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df.plot(x='exercise angina', y='chest pain', style='o')\n",
    "sns.regplot(x=df[\"exercise angina\"], y=df[\"chest pain\"], fit_reg=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df.plot(x='exercise angina', y='chest pain', style='o')\n",
    "sns.regplot(x=df[\"cholestoral\"], y=df[\"diagnosis\"], fit_reg=True)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df.plot(x='blood pressure(r)', y='cholestoral', style='o')\n",
    "sns.regplot(x=df[\"blood pressure(r)\"], y=df[\"cholestoral\"], fit_reg=True)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graph = df.groupby(['age'])['age'].count()\n",
    "graph.plot(kind = 'bar', figsize=(16, 10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "graph = df.groupby(['sex'])['sex'].count()\n",
    "graph.plot(kind = 'bar', figsize=(16, 10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# On nettoie les valeurs nulles\n",
    "df = df[df[\"number of vessels\"].str.contains(\"\\?\")==False]\n",
    "df = df[df[\"thalassemia\"].str.contains(\"\\?\")==False]\n",
    "\n",
    "df.describe()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max = MinMaxScaler()\n",
    "\n",
    "df_minmax = min_max.fit_transform(df)\n",
    "df_minmax = pd.DataFrame(df_minmax)\n",
    "df_minmax.boxplot(rot = 45,figsize=(16, 10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "df_scale = scale(df)\n",
    "df_scale\n",
    "pd.DataFrame(df_scale).boxplot(rot = 45,figsize=(16, 10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# take only most important columns\n",
    "X = df_minmax.iloc[:,[0,2,7,8,9,10]]\n",
    "# X = df_minmax.iloc[:,0:13]\n",
    "y = df_minmax.iloc[:,-1]\n",
    "\n",
    "# print(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/4, random_state=42, stratify=y)\n",
    "\n",
    "# FIXME : Restore initial classes\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "le.fit(y_test)\n",
    "y_test = le.transform(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Entraîner le modèle"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.effective_metric_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prédir"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = knn.predict(X_test)\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def evaluate_this(y_test,y_pred):\n",
    "    print(metrics.accuracy_score(y_test, y_pred))\n",
    "    print(metrics.f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "evaluate_this(y_test,y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try to guess better K"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## k-fold cross validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# https://towardsdatascience.com/how-to-find-the-optimal-value-of-k-in-knn-35d936e554eb pour l'approche basique\n",
    "# https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/ pour le cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# creating odd list of K for KNN\n",
    "neighbors = list(range(1, 50, 2))\n",
    "\n",
    "cv_scores = []\n",
    "error_rate = []\n",
    "\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(y_pred != y_test))\n",
    "\n",
    "# changing CV accuracy => to CV error\n",
    "cv_errors = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k for both methods\n",
    "cv_optimal_k = neighbors[cv_errors.index(min(cv_errors))]\n",
    "error_optimal_k = neighbors[error_rate.index(min(error_rate))]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(neighbors, cv_errors, color='green', linestyle='dashed', \n",
    "         marker='o', markersize=6)\n",
    "\n",
    "plt.plot(neighbors, error_rate, color='grey', linestyle='dashed', \n",
    "         marker='o', markersize=6)\n",
    "\n",
    "\n",
    "plt.title('CV errors AND Erros VS K')\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error rate\")\n",
    "\n",
    "print(\"Minimum CV error : \", min(cv_errors),\" % at K =\", cv_optimal_k)\n",
    "print(\"Minimum error: \", min(error_rate),\" % at K =\", error_optimal_k)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Best K is 17 !\n",
    "\n",
    "> 5 seems good, but it is probably overfiting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame({\"neighbors\" : neighbors, \"CV errors\" : cv_errors, \"Errors\" : error_rate}, index=neighbors)\n",
    "# df = df.sort_values('errors', ascending=True)\n",
    "df = df.sort_values(['CV errors', 'neighbors'], ascending=[True, False])\n",
    "df.head(15)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Rerun model with new K"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "K = 15\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=K)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "evaluate_this(y_test, y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision boudaries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First -- bad -- method : take multiple features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "import sys\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "X_new = X.values[:, [0,4]]\n",
    "le.fit(y.values)\n",
    "y_new = le.transform(y.values)\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    knn = KNeighborsClassifier(n_neighbors = K, weights = weights)\n",
    "    knn.fit(X_new, y_new)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X_new[:, 0].min() - 1, X_new[:, 0].max() + 1\n",
    "    y_min, y_max = X_new[:, 1].min() - 1, X_new[:, 1].max() + 1\n",
    "\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X_new[:, 0], X_new[:, 1], c=y, cmap=cmap_bold)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (K, weights))\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instead, find out what are the 2 most important features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### For that, plot feature density"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# All credits go to https://stackoverflow.com/questions/56153726/plot-k-nearest-neighbor-graph-with-8-features \n",
    "\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "\n",
    "def plot_densities(data):\n",
    "    '''\n",
    "    Plot features densities depending on the outcome values\n",
    "    '''\n",
    "    # change fig size to fit all subplots beautifully \n",
    "    rcParams['figure.figsize'] = 15, 20\n",
    "\n",
    "    # separate data based on outcome values \n",
    "    outcome_0 = data[data['diagnosis'] == 0]\n",
    "    # outcome_1 = data[data['diagnosis'] == 1]\n",
    "    outcome_2 = data[data['diagnosis'] == 2]\n",
    "    # outcome_3 = data[data['diagnosis'] == 3]\n",
    "    outcome_4 = data[data['diagnosis'] == 4]\n",
    "\n",
    "    # init figure\n",
    "    fig, axs = plt.subplots(6, 1)\n",
    "    fig.suptitle('Features densities for different outcomes 0/1')\n",
    "    plt.subplots_adjust(left = 0.25, right = 0.9, bottom = 0.1, top = 0.95,\n",
    "                        wspace = 0.2, hspace = 0.9)\n",
    "    count = 0\n",
    "# 0,2,7,8,9,10\n",
    "    # plot densities for outcomes\n",
    "    # for column_name in names[0,2,7,8,9,10]: \n",
    "    for column_name in itemgetter(0,2,7,8,9,10)(names): \n",
    "\n",
    "        ax = axs[count]\n",
    "        #plt.subplot(4, 2, names.index(column_name) + 1)\n",
    "        outcome_0[column_name].plot(kind='density', ax=ax, subplots=True, \n",
    "                                    sharex=False, color=\"blue\", legend=True,\n",
    "                                    label=column_name + ' for Outcome = 0')\n",
    "        outcome_2[column_name].plot(kind='density', ax=ax, subplots=True, \n",
    "                                     sharex=False, color=\"green\", legend=True,\n",
    "                                     label=column_name + ' for Outcome = 2')\n",
    "        outcome_4[column_name].plot(kind='density', ax=ax, subplots=True, \n",
    "                                     sharex=False, color=\"red\", legend=True,\n",
    "                                     label=column_name + ' for Outcome = 4')\n",
    "        ax.set_xlabel(column_name + ' values')\n",
    "        ax.set_title(column_name + ' density')\n",
    "        ax.grid('on')\n",
    "        count = count + 1\n",
    "    plt.show()\n",
    "    fig.savefig('densities.png')\n",
    "\n",
    "# load your data \n",
    "data = pd.read_csv('processed.cleveland.csv', names=['age','sex','chest pain','blood pressure(r)','cholestoral','fasting blood sugar','eleccardio results(r)','max heart rate achvd','exercise angina','ST depression (ex to r)','slope exercise ST','number of vessels','thalassemia','diagnosis'])\n",
    "names = list(data.columns)\n",
    "\n",
    "plot_densities(data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Exercice angina and ST Depression are the more important features !\n",
    "\n",
    "> Furthermore, the correlation between these two is relatively low (0.29; check correlation graph), which means they are not similar. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### You can now draw decision boundarie graph"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> Use the two most important features !"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# All credits go to https://stackoverflow.com/questions/56153726/plot-k-nearest-neighbor-graph-with-8-features \n",
    "\n",
    "import warnings \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import scale\n",
    "# filter warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def classify_and_plot(X, y):\n",
    "    ''' \n",
    "    split data, fit, classify, plot and evaluate results \n",
    "    '''\n",
    "    # split data into training and testing set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 41)\n",
    "\n",
    "    # init vars\n",
    "    n_neighbors = 1\n",
    "    h           = .02  # step size in the mesh\n",
    "\n",
    "    # Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAAAFF'])\n",
    "    cmap_bold  = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "    rcParams['figure.figsize'] = 5, 5\n",
    "    for weights in ['uniform', 'distance']:\n",
    "        # we create an instance of Neighbours Classifier and fit the data.\n",
    "        clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "        y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                             np.arange(y_min, y_max, h))\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        fig = plt.figure()\n",
    "        plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "        # Plot also the training points, x-axis = 'Glucose', y-axis = \"BMI\"\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20)   \n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.title(\"K = %i, weights = '%s')\" % (n_neighbors, weights))\n",
    "        plt.show()\n",
    "        fig.savefig(weights +'.png')\n",
    "\n",
    "data = pd.read_csv('processed.cleveland.csv', names=['age','sex','chest pain','blood pressure(r)','cholestoral','fasting blood sugar','eleccardio results(r)','max heart rate achvd','exercise angina','ST depression (ex to r)','slope exercise ST','number of vessels','thalassemia','diagnosis'])\n",
    "\n",
    "names = list(data.columns)\n",
    "\n",
    "# we only take the best two features and prepare them for the KNN classifier\n",
    "# 3 and 9 are the choosen features\n",
    "X_prime  = np.array(data.iloc[:, [3,9]])\n",
    "# scale X data\n",
    "X        = scale(X_prime)\n",
    "y        = np.array(data.iloc[:,-1])\n",
    "\n",
    "# classify, evaluate and plot results\n",
    "classify_and_plot(X, y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construction de l'arbre"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat_conf = confusion_matrix(y_test, y_pred)\n",
    "mat_conf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "evaluate_this(y_test, y_pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import export_text\n",
    "tree_rules = export_text(tree, feature_names=X_train.columns.values.tolist())\n",
    "# tree_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scores=[]\n",
    "for max_depth in range(2, 10) : \n",
    "    tree=DecisionTreeClassifier(max_depth=max_depth, random_state=42)\n",
    "    tree.fit(X_train, y_train)\n",
    "    score=tree.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "plt.plot(scores)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Algo optimal pr les besoins du plot de l'arbre\n",
    "tree = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize = (10, 10))\n",
    "tree_heart_disease = plot_tree(tree)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tree_rules = export_text(tree, feature_names=X_train.columns.values.tolist())\n",
    "# tree_rules"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}